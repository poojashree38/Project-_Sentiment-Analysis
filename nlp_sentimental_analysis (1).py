# -*- coding: utf-8 -*-
"""NLP_Sentimental Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Autn2KRv7t2YgbcxOetv3m2tzMl9K6R

# EDA
"""

!pip install wordcloud

"""# Load the Libraries"""

# Import the necessary libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Load the dataset

df = pd.read_csv("reviews.csv")

# Basic data overview

df

# Reset the index and set it to start from 1
df.reset_index(drop=True, inplace=True)
df.index = df.index + 1
df.index.name = 'SI.No'

# Renaming the columns
df_1 = df.rename({'headline':'Headline','reviewBody':'Review','ratingValue':'Ratings'},axis=1)

# Inspect the first few rows
df_1.head()

df_1.tail()

df_1.shape

#datatypes
df_1.dtypes

df_1.info()

df_1.describe()

df_1.isnull().sum()

# Check for missing values

df_1['Ratings'].unique()

df_1[df_1['Ratings'].isnull()]

# Summary statistics of the numerical column
print(df_1['Ratings'].describe())

# Data cleaning and preprocessing
# Assuming the dataset has columns 'review' for text and 'sentiment' for labels
df_1.dropna(inplace=True)

df_1

duplicate_rows = df_1[df_1.duplicated()]
print("Number of duplicate rows:", len(duplicate_rows))

df_1.drop_duplicates(inplace=True)
df_1.reset_index(drop=True, inplace=True)

print("Number of rows after removing duplicates:", len(df_1))

df_1

df.shape

"""#  Basic visualizations"""

# Distribution of Ratings
plt.figure(figsize=(8, 6))
sns.countplot(data=df_1, x='Ratings')  # Replace 'ratingValue' with the correct column name for sentiment
plt.title('Distribution of Ratings')
plt.xlabel('Ratings')
plt.ylabel('Count')
plt.show()

# Add a column for text length
df_1['text_length'] = df_1['Review'].apply(len)

# Plot the distribution of text length
plt.figure(figsize=(8, 6))
sns.histplot(df_1['text_length'], bins=50, kde=True)
plt.title('Review Text Length Distribution')
plt.xlabel('Text Length')
plt.ylabel('Frequency')
plt.show()

#Distribution of Headline
#Bar graph to visualize the total counts of each headline

df_1['Headline'].value_counts().plot.bar(color = 'orange')
plt.title('Headline distribution count')
plt.xlabel('headline')
plt.ylabel('Count')
plt.show()

plt.hist(df_1["Ratings"])
plt.show()
#Histogram

#plt.legend()

print(df_1["Ratings"].value_counts())
df_1.Ratings.value_counts().plot(kind="pie", autopct='%1.1f%%')
plt.title('Rating Value Distribution')
#plt.ylabel('')
plt.show()


#pie chart

#boxplot
plt.boxplot(df_1["Ratings"])
plt.show()

"""## Data Preprocessing

Handling missing values
"""

# Fill missing values
df_1['Review'].fillna('', inplace=True)
df_1['Ratings'].fillna('', inplace=True)

"""Text Preprocessing
#Clean and preprocess the text data.
"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Download necessary NLTK data
nltk.download('stopwords')
nltk.download('wordnet')

# Initialize the lemmatizer
lemmatizer = WordNetLemmatizer()

# Function to preprocess text
def preprocess_text(text):
    # Remove special characters and numbers
    text = re.sub('[^a-zA-Z]', ' ', text)
    # Convert to lowercase
    text = text.lower()
    # Tokenize
    words = text.split()
    # Remove stopwords and lemmatize
    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]
    return ' '.join(words)

# Apply preprocessing
df_1['cleaned_text'] = df_1['Review'].apply(preprocess_text)

!pip install vaderSentiment

import pandas as pd
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
# Initialize VADER Sentiment Analyzer
analyzer = SentimentIntensityAnalyzer()

# Function to get sentiment
def get_sentiment_vader(text):
    score = analyzer.polarity_scores(text)
    if score['compound'] >= 0.05:
        return 'Positive'
    elif score['compound'] <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

# Apply function to the dataframe
df_1['sentiment'] = df_1['cleaned_text'].apply(get_sentiment_vader)
print(df)

df_1.head()

df_1 = df_1.drop(columns=['Review','Ratings'])

df_1 = df_1.drop(columns=['Headline','text_length'])

df_1.head()

"""Feature Engineering
#Convert text data into numerical data using TF-IDF.

Encode target labels.
"""

from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
# Splitting Data
X = df_1['cleaned_text']
y = df_1['sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorization
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Handling Imbalance using SMOTE
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train)



"""## Model Building and Deployment

Model Selection and Training

#Train multiple models and evaluate them.
"""

# Logistic Regression
lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train_res, y_train_res)

# Prediction and Evaluation
y_pred_lr = lr_model.predict(X_test_tfidf)
print("Logistic Regression:")
print(confusion_matrix(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))
print('Accuracy:', accuracy_score(y_test, y_pred_lr))

from sklearn.naive_bayes import MultinomialNB

# Naive Bayes
nb_model = MultinomialNB()
nb_model.fit(X_train_res, y_train_res)

# Prediction and Evaluation
y_pred_nb = nb_model.predict(X_test_tfidf)
print("Naive Bayes:")
print(confusion_matrix(y_test, y_pred_nb))
print(classification_report(y_test, y_pred_nb))
print('Accuracy:', accuracy_score(y_test, y_pred_nb))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Model Training
model = RandomForestClassifier(n_estimators=10, random_state=33)
model.fit(X_train_res, y_train_res)

# Prediction and Evaluation
y_pred = model.predict(X_test_tfidf)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print('Accuracy:', accuracy_score(y_test, y_pred))

"""# **Saving Model**"""

import joblib

# Save the trained model to a file
joblib.dump(model, 'random_forest_model.pkl')

# Save the TfidfVectorizer
joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')

import pickle

# Save the trained model
with open('random_forest_model.pkl', 'wb') as file:
    pickle.dump(model, file)

# Save the TfidfVectorizer
with open('tfidf_vectorizer.pkl', 'wb') as file:
    pickle.dump(vectorizer, file)